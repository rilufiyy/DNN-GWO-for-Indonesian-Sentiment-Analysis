# -*- coding: utf-8 -*-
"""Sri Lutfiya Dwiyeni_Mini Project Assignment Day 34_AIML 8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LUjtmf_SoJT7nX5QexqLg_6r_h0pQtOm

# Import Libraries
"""

!pip install --upgrade nlp-id

!pip install pandas numpy scikit-learn tensorflow matplotlib seaborn gensim keras-tuner

!pip install -U gensim

!pip install -q tensorflow-text

import tensorflow as tf
print("TF OK:", tf.__version__)

import warnings
warnings.filterwarnings('ignore')

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import keras_tuner as kt
import nltk
from nltk.corpus import stopwords
import random
from sklearn.utils import class_weight

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from nlp_id.lemmatizer import Lemmatizer
from nlp_id.stopword import StopWord
from keras import layers, models
from keras.callbacks import EarlyStopping, ModelCheckpoint

import gensim
from gensim.models import Word2Vec

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping

random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

try:
    import gensim
    from gensim.models import Word2Vec
    gensim_available = True
except Exception:
    gensim_available = False

"""# Load Dataset"""

train_dataset_path = 'https://raw.githubusercontent.com/IndoNLP/indonlu/master/dataset/smsa_doc-sentiment-prosa/train_preprocess.tsv'
valid_dataset_path = 'https://raw.githubusercontent.com/IndoNLP/indonlu/master/dataset/smsa_doc-sentiment-prosa/valid_preprocess.tsv'

test_dataset_path = 'https://raw.githubusercontent.com/IndoNLP/indonlu/master/dataset/smsa_doc-sentiment-prosa/test_preprocess.tsv'

def load_tabular(path):
    df = pd.read_csv(path, sep='\t', header=None, names=['Text', 'Sentiment'])
    return df

print("Loading datasets...")
train_df = load_tabular(train_dataset_path)
valid_df = load_tabular(valid_dataset_path)
test_df = load_tabular(test_dataset_path)

print("Train shape:", train_df.shape)
print("Valid shape:", valid_df.shape)
print("Test shape:", test_df.shape)

print("\nSample labels (train):")
print(train_df['Sentiment'].value_counts())

train_df.head()

train_df.columns

train_df.info()

valid_df.head()

test_df.head()

"""## Data Understanding
Berdasarkan hasil eksekusi di atas, berikut merupakan ringkasan analisis awal terhadap dataset yang digunakan:
1. Informasi Dasar & Struktur Data

    a. Ukuran Data: Dataset terdiri  dari tiga bagian:
      - Train set: 11.000 sampel
      - Validation set: 1.066 sampel
      - Test set: 1.066 sampel

    b. Berdasarkan jumlah kolom:
      - Kolom Text berisi kalimat atau opini dalam Bahasa Indonesia
      - Kolom Sentiment berisi label kategori untuk setiap kalimat

    c. Berdasarkan tipe data:
      - Kolom Text bertipe object (string)
      - Kolom Sentiment bertipe object/string yang berisi label kategorikal seperti positive, negative, dan neutral

2. Analisis Distribusi Sentimen
Distribusi kelas pada train set menunjukkan ketidakseimbangan kelas yang cukup signifikan, di antaranya ialah: positive sebanyak 6.416 sampel, negative sebanyak 3.426 sampel, dan neutral sebanyak 1.148 sampel.

Berdasarkan hal tersebut, dataset mengalami ketidakseimbangan pada proporsi label yang dapat memengaruhi performa model, terutama pada kelas minoritas seperti neutral, yang cenderung memiliki nilai recall atau F1-score lebih rendah. Hal ini penting untuk dipertimbangkan dalam evaluasi model dan penggunaan metrik seperti macro F1-score.

# Exploratory Data Analysis (EDA)

## Distribution of Sentiment
"""

plt.figure(figsize=(8, 6))
sns.countplot(x = train_df['Sentiment'], palette = 'viridis')
plt.title('Sentiment Distribution')
plt.ylabel('Count')
plt.xlabel('Sentiment')
plt.show()

sentiment_distribution = train_df['Sentiment'].value_counts()
print("\Sentiment Distribution Count:")
print(sentiment_distribution)

"""**Penjelasan insight:** Berdasarkan visualisasi di atas, diperoleh bahwa:
- Kelas positive memiliki jumlah data paling banyak, menunjukkan mayoritas kalimat dalam dataset bernada positif.
- Kelas neutral adalah yang paling sedikit, sehingga kemungkinan besar akan menjadi kelas yang paling sulit diprediksi.
- Kelas negative berada di posisi tengah, masih cukup banyak namun tetap jauh lebih sedikit dibanding positive.

Dengan demikian dapat dikatakan bahwa distribusi data tidak seimbang (imbalanced), sehingga model berpotensi lebih bias terhadap kelas positive. Oleh karena itu penting untuk menggunakan metrik seperti Macro F1-Score agar evaluasi performa antar kelas tetap adil.
"""

train_df['character_length'] = train_df['Text'].apply(lambda x: len(x))
print("\nDescriptive Statistics of Character Length in Training Data:")
print(train_df['character_length'].describe())

plt.figure(figsize=(12,8))
sns.histplot(train_df['character_length'], bins=50, kde=True, color='orange')
plt.title('Distribution of Character Length')
plt.xlabel('Count')

"""**Penjelasan insight:** Dari grafik visualisasi di atas, diperoleh bahwa:
- Mayoritas teks memiliki panjang karakter 50-200, menunjukkan bahwa data cenderung berupa kalimat pendek hingga sedang.
- Terdapat beberapa teks yang sangat panjang (300-500 karakter), namun jumlahnya relatif sedikit.
- Distribusi condong ke kanan (right-skewed), dapat diartikan bahwa lebih banyak teks pendek daripada teks panjang.
- Puncak distribusi (mode) berada sekitar 100-150 karakter, menandakan rentang ini paling umum.
- Adanya variasi panjang teks cukup besar, tetapi teks ekstrem (sangat panjang) jarang.

Sedemikian sehingga dataset IndoNLU SMSA cocok untuk model berbasis TF-IDF, karena mayoritas kalimat tidak terlalu panjang.
"""

sns.kdeplot(data = train_df, x='character_length', hue='Sentiment', palette = ['g', 'b', 'r'], fill=True)

"""**Penjelasan insight:** Berdasarkan grafik visualisasi di atas, diperoleh beberapa insight di antaranya ialah sebagai berikut:
- Untuk label positive memiliki panjang karakter paling bervariasi, dari pendek hingga sangat panjang (hingga 40-500 karakter). Artinya kalimat positif cenderung lebih panjang dan lebih detail.
- Pada label negative, panjang karakter berada di tengah, umumnya 80-200 karakter. Kalimat negatif biasanya cukup jelas tetapi tidak sepanjang kalimat positif.
- Sedangkan untuk label neutral memiliki panjang karakter paling pendek, mayoritas hanya 40-120 karakter. Kalimat netral cenderung singkat, langsung pada inti informasi.

## The 20 Most Common Sentiment Label Words
"""

def plot_top_words(Sentiment, stop_words=None, color='skyblue'):
    subset = train_df[train_df['Sentiment'] == Sentiment]

    cv = CountVectorizer(ngram_range=(1, 2), stop_words=stop_words or None)
    cv_fit = cv.fit_transform(subset['Text'])

    word_freq = pd.DataFrame(cv_fit.toarray(), columns=cv.get_feature_names_out())
    word_freq_sum = word_freq.sum().sort_values(ascending=False)

    plt.figure(figsize=(10, 6))
    sns.barplot(
        y=word_freq_sum.head(20).index,
        x=word_freq_sum.head(20).values,
        palette=[color] * 20
    )

    plt.title(f"Top 20 Words ({Sentiment})")
    plt.xlabel("Frequency")
    plt.ylabel("Words")
    plt.show()

plot_top_words('positive', color='green')
plot_top_words('neutral', color='grey')
plot_top_words('negative', color='red')

"""**Penjelasan insight:** Diperoleh beberapa insight dari grafik visualisasi di atas:

a. Insight dari Kata Positif
- Kata “enak”, “makanan”, “tempat” mendominasi, menunjukkan ulasan positif banyak membahas kualitas rasa dan pengalaman saat berkunjung.
- Frekuensi tinggi kata umum seperti “nya”, “yang”, “dan”, “di” menandakan struktur kalimat panjang dan deskriptif.
- Munculnya kata “harga”, “sangat”, “juga” menunjukkan bahwa penilaian positif sering disertai detail tambahan seperti harga atau tingkat kepuasan.
- Kehadiran kata “bandung” menunjukkan banyak ulasan positif terkait lokasi tertentu (misal tempat kuliner di Bandung).
- Secara umum, ulasan positif lebih fokus pada kualitas makanan, suasana tempat, dan pengalaman menyenangkan.

b. Insight dari Kata Netral
- Kata-kata netral didominasi oleh kata fungsional seperti “di”, “yang”, “dan”, menandakan kalimat informatif tanpa penilaian emosional.
- Munculnya kata “demokrat”, “2018”, “pilkada”, “partai” menunjukkan bahwa dataset opini netral banyak membahas topik politik atau berita, bukan pengalaman pribadi.
- Kata “tidak”, “akan”, “sudah” sering dipakai untuk memberikan penjelasan atau fakta, bukan penilaian.
- Ulasan netral tidak fokus pada makanan atau tempat, melainkan pada informasi dan konteks situasi.
- Pola ini menegaskan bahwa sentimen netral digunakan untuk deskripsi tanpa emosi.

c. Insight dari Kata Negatif
- Kata “tidak” sangat dominan, menunjukkan mayoritas ulasan negatif berisi ekspresi ketidakpuasan
- Banyaknya kata seperti “saja”, “itu”, “sudah”, “tapi”, “kalau” menunjukkan pengguna sering membandingkan atau menolak ekspektasi
- Kata “makanan” tetap muncul, menunjukkan bahwa meskipun ulasan negatif, topiknya tetap banyak terkait kualitas makanan yang mengecewakan.
- Kehadiran kata “orang”, “saya”, “dia” mengindikasikan adanya keluhan terkait pelayanan atau interaksi dengan staf.
- Kata umum seperti “yang”, “dan”, “di” tetap mendominasi, menandakan ulasan negatif cenderung panjang dan penuh penjelasan detail.
- Ulasan negatif umumnya berfokus pada ketidaksesuaian, pelayanan buruk, atau makanan yang tidak memuaskan.
"""

stopword = StopWord()
stopword.get_stopword()

indonesian_stopwords = stopword.get_stopword()

indonesian_stopwords

lemmatizer = Lemmatizer()
def lemmatization(text):
    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split() if word in text)
    return text
train_df['Text'] = train_df['Text'].apply(lemmatization)
valid_df['Text'] = valid_df['Text'].apply(lemmatization)

train_df.head(20)

additional_stopwords = ['nya', 'ya', 'sih', 'baiknya',
                        'berkali', 'kali', 'kurangnya', 'mata', 'gue',
                        'olah', 'sekurang', 'setidak', 'tama', 'tidaknya', 'banget'
                        ]

combined_stop_words = list(indonesian_stopwords) + additional_stopwords

combined_stop_words.remove('tidak')
combined_stop_words.remove('tapi')

plot_top_words('positive', stop_words=combined_stop_words)
plot_top_words('neutral', stop_words=combined_stop_words)
plot_top_words('negative', stop_words=combined_stop_words)

"""**Penjelasan insight:** Setelah dilakukannya lemmatization, diperoleh beberapa insight yaitu:

a. Insight: Positive Words (Setelah Lemmatization)
- “makan” dan “enak” menjadi kata paling dominan, menandakan bahwa ulasan positif mayoritas berfokus pada kualitas rasa makanan.
- Munculnya kata “harga”, “menu”, “restoran”, “suasana”, “nyaman”, “layan” menunjukkan bahwa ulasan positif tidak hanya tentang makanan, tetapi juga harga yang sesuai, pelayanan yang baik, dan suasana tempat yang nyaman.
- Kata “bandung”, “malam”, “jalan” menunjukkan bahwa banyak ulasan positif berkaitan dengan lokasi wisata/kuliner tertentu dan pengalaman makan di waktu tertentu (misalnya malam hari).
- Kehadiran kata seperti “pilih”, “coba”, “suka” menandakan bahwa pelanggan cenderung merekomendasikan atau memilih ulang produk/jasa tersebut.
- Kata makanan spesifik seperti “ayam”, “goreng”, “pandang” menegaskan bahwa ulasan positif sering menyebut menu specific favorit

b. Insight: Neutral Words (Setelah Lemmatization)
- Kata paling dominan seperti “demokrat”, “pilkada”, “2018”, “partai”, “anies”, “jakarta”, “pdip”, “kamil”, “ridwan kamil” menunjukkan bahwa ulasan netral didominasi oleh topik politik, tokoh politik, dan peristiwa pemilu.
- Banyak kata nama tokoh seperti “novanto”, “jokowi”, “menteri” yang memperkuat bahwa neutral sentiment mengandung berita dan opini informatif, bukan penilaian positif/negatif.
- Kata “tidak” muncul namun konteksnya netral, menandakan penjelasan informatif, bukan keluhan.
- Kehadiran kata geografis seperti “indonesia”, “jawa”, “jakarta” menunjukkan bahwa ulasan netral juga terkait informasi negara, wilayah, atau kebijakan daerah.
- Secara umum, ulasan netral tidak berbicara tentang makanan atau pelayanan, melainkan isu publik, berita, dan politik.

c. Insight: Negative Words (Setelah Lemmatization)
- “tidak” menjadi kata negatif paling dominan, konsisten dengan ekspresi penolakan / ketidakpuasan dalam ulasan negatif.
- Munculnya kata “makan”, “enak” dalam konteks negatif menunjukkan bahwa pelanggan menilai makanan tidak enak atau mengecewakan.
- Kata terkait pelayanan seperti “layan”, “pesan”, “orang” menandakan adanya keluhan terkait pelayanan, pengalaman memesan, atau interaksi dengan staf.
- “harga”, “mahal” menunjukkan banyak keluhan tentang harga yang dianggap tidak sepadan dengan kualitas.
- Kata emosional seperti “kecewa”, “marah” memperkuat bahwa ulasan negatif berisi ketidakpuasan yang jelas dan emosional.
- Munculnya kata “jokowi”, “indonesia”, “indosat” menunjukkan adanya ulasan negatif terkait layanan publik, kebijakan, atau brand tertentu, bukan sekadar makanan.
- Kata “tapi”, “pilih”, “nyata” sering muncul dalam kalimat pembanding atau kritik yang menjelaskan alasan ketidakpuasan secara detail.
- Kata “jalan” dapat merujuk pada akses sulit, lokasi tidak nyaman, atau pengalaman perjalanan yang buruk.

Setelah proses cleaning awal dan lemmatization dilakukan, kata-kata yang muncul menjadi lebih fokus dan representatif karena bentuk jamak maupun imbuhan telah distandarkan, sehingga maknanya lebih konsisten (misalnya “makanan” menjadi “makan”). Pada kategori positif, kata-kata yang dominan kini lebih jelas menggambarkan aspek-aspek seperti rasa, harga, pelayanan, suasana, serta kecenderungan pengguna untuk merekomendasikan atau mencoba kembali. Sementara itu, kategori netral tetap didominasi oleh topik politik dan berita, menunjukkan bahwa opini yang bersifat informatif atau deskriptif sangat berbeda konteksnya dibandingkan dua kategori lainnya. Pada kategori negatif, hasil lemmatization membuat keluhan semakin terlihat jelas, terutama terkait ketidakpuasan terhadap rasa, harga, pelayanan, maupun isu publik tertentu. Secara keseluruhan, proses lemmatization membantu mempertegas karakteristik masing-masing sentimen dan meningkatkan kejelasan interpretasi.

# Data Preprocessing
"""

def clean_text(text):
    import re
    import string
    text = str(text).lower()
    text = re.sub('\[/(){}\[\]\|@,;]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

train_df['Text'] = train_df['Text'].apply(lambda x: clean_text(x))
val_model_evaluation = valid_df.copy()

valid_df['Text'] = valid_df['Text'].apply(lambda x: clean_text(x))

"""## Missing Values Checking"""

train_df.isna().any()

"""**Penjelasan insight:** Setelah dilakukannya pengecekan missing value, tidak ditemukan adanya missing value pada dataset IndoNLU SMSA."""

train_df.duplicated().sum()

"""**Penjelasan insight:** Setelah dilakukannya pengecekan duplikat data, dataset IndoNLU SMSA terindikasi adanya duplikat data sebanyak 67 baris."""

train_df[train_df.duplicated(keep=False)==True].head(10)

train_df[train_df.duplicated(subset=['Text'], keep=False)]

train_df.drop_duplicates(subset=['Text', 'Sentiment'], inplace=True)

train_df[train_df.duplicated(subset=['Text'], keep=False)]

conflict = train_df.groupby('Text')['Sentiment'].nunique()
conflict_texts = conflict[conflict > 1].index

train_df = train_df[~train_df['Text'].isin(conflict_texts)]

train_df.groupby('Text')['Sentiment'].nunique().max()

"""**Penjelasan insight:** Sebelumnya terindikasi terdapat duplikat data, lalu saya menangani duplikasi data berdasarkan kombinasi Text-Sentiment sehingga tidak ada lagi baris yang benar-benar sama (duplikat). Semua teks yang memiliki lebih dari satu label sentimen atau yang disebut dengan conflicting labels sudah dibuang, dataset IndoNLU SMSA yang saya gunakan sekarang hanya berisi data yang labelnya konsisten untuk setiap teks.

## Encode Label
"""

le = LabelEncoder()
y_train = le.fit_transform(train_df['Sentiment'])
y_valid = le.transform(valid_df['Sentiment'])
y_test  = le.transform(test_df['Sentiment'])
print("Classes:", le.classes_)

"""# Modeling Deep Neural Network (DNN) TF-IDF

## Vectorization
"""

tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2))
X_train_tfidf = tfidf.fit_transform(train_df['Text']).toarray()
X_valid_tfidf = tfidf.transform(valid_df['Text']).toarray()
X_test_tfidf  = tfidf.transform(test_df['Text']).toarray()
input_dim = X_train_tfidf.shape[1]
print("TF-IDF dim:", input_dim)

def build_dnn(input_dim, n_neurons=256, dropout=0.3, lr=1e-3):

    model = models.Sequential([
        layers.Input(shape=(input_dim,)),
        layers.Dense(n_neurons, activation='relu'),
        layers.Dropout(dropout),
        layers.Dense(128, activation='relu'),
        layers.Dropout(dropout),
        layers.Dense(64, activation='relu'),
        layers.Dense(3, activation='softmax')
    ])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=lr),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

model = build_dnn(input_dim)
model.summary()

input_dim = X_train_tfidf.shape[1]

base_model = build_dnn(input_dim)

es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = base_model.fit(
    X_train_tfidf, y_train,
    validation_data=(X_valid_tfidf, y_valid),
    epochs=20,
    batch_size=32,
    callbacks=[es],
    verbose=1
)

val_pred = np.argmax(base_model.predict(X_valid_tfidf), axis=1)
test_pred = np.argmax(base_model.predict(X_test_tfidf), axis=1)

print("Validation Accuracy:", accuracy_score(y_valid, val_pred))
print(classification_report(y_valid, val_pred, target_names=le.classes_))

val_cm = confusion_matrix(y_valid, val_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Validation Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""**Penjelasan insight:** Berdasarkan evaluasi model di atas, diperoleh beberapa insight yaitu:
1. Validasi accuracy sebesar 0.8769 yang diperoleh menunjukkan bahwa model sudah mampu memprediksi sentimen dengan baik pada data validasi. Artinya, sebagian besar kalimat berhasil diklasifikasikan dengan benar.

2. Performa model DNN TFIDF sangat baik untuk kelas positive, dengan precision 0.94 dalam hal prediksi "positive" jarang salah, serta recall nya 0.89 hampir semua data positif berhasil dikenali polanya oleh model. Banyak data positif (support 735), jadi model lebih “belajar” dari pola komentar positif.

3. Kelas negative juga stabil memiliki precision 0.82 dan recall 0.87. Artinya model DNN TFIDF ini dapat mengenali kalimat negatif, dan tidak terlalu sering salah dalam memprediksi kalimat negatif.

4. Kelas neutral masih paling sulit dibedakan dengan precision 0.73, recall 0.79, dan F1 score nya paling rendah dari 3 kelas yang ada. Pada confusion matrix terlihat bahwa 15 data neutral dikira negative, 12 data neutral dikira positive, 20 data positive dikira neutral, dan 18 data negative dikira neutral. Hal ini terjadi karena kalimat neutral sering mirip positif/negatif (ambigu), sehingga model kesulitan menangkap pola.

5. Model sedikit bias ke positive dapat dilihat pada confusion matrix terdapat 58 data positive yang diprediksi negative, tetapi tetap model confident untuk memprediksi label positive sebanyak 657 benar diprediksi. Hal ini wajar karena jumlah data positif jauh lebih banyak dengan support 735, TF-IDF sensitif terhadap kata-kata umum yang sering muncul di komentar positif.

6. Untuk macro dan weighted average mendekati, dengan macro F1 nya yaitu 0.84 dan weighted F1 nya yaitu 0.88. Hal tersebut mengindentifikasikan bahwa model konsisten performanya di semua kelas, tetapi tetap lebih bagus di kelas besar yaitu dalam hal prediksi kelas positive.

Secara keseluruhan dapat disimpulkan bahwa Model DNN + TF-IDF sudah bekerja sangat baik, terutama pada sentimen positive dan negative.
Kelas neutral masih paling sulit dibedakan karena sifat kalimatnya yang ambigu. Dengan akurasi validasi hampir 88%, model sudah tergolong kuat untuk tugas sentiment analysis.

## Hyperparameter Tuning DNN TF-IDF using Grey Wolf Optimizer (GWO)
"""

def fitness_function(params, X_train, y_train, X_val, y_val, input_dim):

    n_neurons = int(params[0])
    dropout   = float(params[1])
    lr        = float(params[2])
    batch     = int(params[3])

    model = build_dnn(
        input_dim=input_dim,
        n_neurons=n_neurons,
        dropout=dropout,
        lr=lr
    )

    early_stop = EarlyStopping(
        monitor='val_accuracy',
        patience=3,
        restore_best_weights=True
    )

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=15,
        batch_size=batch,
        verbose=0,
        callbacks=[early_stop]
    )

    val_acc = max(history.history['val_accuracy'])
    return val_acc, model, history

def GWO(X_train, y_train, X_val, y_val, input_dim, num_wolves=5, max_iter=10):
    bounds = [
        (64, 512),
        (0.1, 0.5),
        (1e-4, 1e-2),
        (16, 128)
    ]

    dim = len(bounds)

    wolves = np.array([
        [np.random.uniform(low, high) for (low, high) in bounds]
        for _ in range(num_wolves)
    ])

    alpha, beta, delta = None, None, None
    alpha_score, beta_score, delta_score = -np.inf, -np.inf, -np.inf
    alpha_model, alpha_history = None, None

    for iter in range(max_iter):

        for i in range(num_wolves):

            score, model, history = fitness_function(
                wolves[i],
                X_train, y_train,
                X_val, y_val,
                input_dim
            )

            if score > alpha_score:
                delta, delta_score = beta, beta_score
                beta, beta_score = alpha, alpha_score
                alpha, alpha_score = wolves[i].copy(), score
                alpha_model = model
                alpha_history = history

            elif score > beta_score:
                delta, delta_score = beta, beta_score
                beta, beta_score = wolves[i].copy(), score

            elif score > delta_score:
                delta, delta_score = wolves[i].copy(), score

        a = 2 - iter * (2 / max_iter)

        for i in range(num_wolves):
            for d in range(dim):

                r1, r2 = np.random.rand(), np.random.rand()
                A1 = 2*a*r1 - a
                C1 = 2*r2
                D_alpha = abs(C1 * alpha[d] - wolves[i][d])
                X1 = alpha[d] - A1 * D_alpha

                r1, r2 = np.random.rand(), np.random.rand()
                A2 = 2*a*r1 - a
                C2 = 2*r2
                D_beta = abs(C2 * beta[d] - wolves[i][d])
                X2 = beta[d] - A2 * D_beta

                r1, r2 = np.random.rand(), np.random.rand()
                A3 = 2*a*r1 - a
                C3 = 2*r2
                D_delta = abs(C3 * delta[d] - wolves[i][d])
                X3 = delta[d] - A3 * D_delta

                wolves[i][d] = (X1 + X2 + X3) / 3
                low, high = bounds[d]
                wolves[i][d] = np.clip(wolves[i][d], low, high)

        print(f"Iter {iter+1}/{max_iter} | Best Val Acc: {alpha_score:.4f}")

    return alpha, alpha_model, alpha_history

best_params, best_gwo_model, best_history = GWO(
    X_train_tfidf, y_train,
    X_valid_tfidf, y_valid,
    input_dim,
    num_wolves=5,
    max_iter=5
)

print("\nBest Hyperparameters:")
print("Neurons:", int(best_params[0]))
print("Dropout:", float(best_params[1]))
print("Learning Rate:", float(best_params[2]))
print("Batch Size:", int(best_params[3]))

val_pred_prob = best_gwo_model.predict(X_valid_tfidf)
val_pred = np.argmax(val_pred_prob, axis=1)

print("Validation Accuracy (GWO Tuned):", accuracy_score(y_valid, val_pred))
print(classification_report(y_valid, val_pred, target_names=le.classes_))

val_cm = confusion_matrix(y_valid, val_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Validation Confusion Matrix (GWO Tuned)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""**Penjelasan insight:** Berdasarkan hasil evaluasi model setelah dilakukan tuning menggunakan Grey Wolf Optimizer (GWO), diperoleh beberapa insight penting terkait performa model:

1. Validation accuracy meningkat menjadi 0.895, atau sekitar 89,5%. Artinya, model sudah sangat baik dalam memprediksi sentimen pada data validasi, dengan proporsi prediksi benar yang lebih tinggi dibandingkan versi sebelum tuning.

2. Performa model pada kelas positive menjadi yang terbaik.
Precision sebesar 0.94 menunjukkan bahwa prediksi “positive” sangat jarang salah. Recall 0.92 menandakan bahwa sebagian besar data positive berhasil dikenali. Support kelas ini paling besar (735 data), sehingga model memiliki lebih banyak contoh untuk mempelajari pola kalimat positif; kondisi ini memperkuat akurasinya dalam menangani kelas tersebut.

3. Performa kelas negative juga solid, dengan precision 0.85 dan recall 0.89. Artinya model cukup andal dalam mengenali dan memprediksi sentimen negative. Confusion matrix memperlihatkan bahwa sebagian besar data negative diklasifikasikan dengan benar (351 data benar diprediksi), dan kesalahan prediksi utamanya mengarah ke kelas positive sebanyak 32 data.

4. Kelas neutral tetap menjadi kelas yang paling menantang, dengan precision 0.80, recall 0.78, dan F1-score 0.79—yang merupakan nilai terendah di antara ketiga kelas. Pada confusion matrix terlihat beberapa pola yang kurang tepat, di antaranya ialah:
    - 16 data neutral diprediksi negative
    - 13 data neutral diprediksi positive
    - 15 data positive diprediksi neutral
    - 11 data negative diprediksi neutral

    Hal ini menunjukkan bahwa kalimat neutral masih cenderung ambigu dan sering memiliki kemiripan struktur atau kata kunci dengan kalimat positif maupun negatif. Tantangan ini bersifat umum dalam tugas sentiment analysis.

5. Model menunjukkan sedikit kecenderungan pada kelas positive, didukung oleh jumlah prediksi benar yang sangat tinggi (675). Walaupun terdapat 45 data positive yang salah diklasifikasikan sebagai negative, dominasi data positive dalam dataset tetap membuat model lebih confident pada kelas ini. TF-IDF juga sensitif terhadap variasi kata yang sering muncul pada komentar positif sehingga pola tersebut tertangkap lebih kuat.

6. Perbandingan macro average dan weighted average menunjukkan kestabilan performa.
Macro F1 berada pada angka 0.86, sementara weighted average F1 juga 0.90. Hal ini mengindikasikan bahwa meskipun dataset tidak seimbang, performa model tetap konsisten namun cenderung lebih optimal pada kelas dengan jumlah data lebih besar (positive dan negative).

Secara keseluruhan, model DNN TF-IDF yang telah dioptimasi dengan GWO memberikan peningkatan performa dan bekerja sangat baik dalam memprediksi sentimen, khususnya untuk kelas positive dan negative. Tantangan terbesar tetap terdapat pada kelas neutral karena sifatnya yang ambigu dan overlap semantik dengan dua kelas lainnya. Dengan akurasi validasi mendekati 90%, model dapat dikatakan sangat kompetitif dan reliabel untuk digunakan dalam tugas sentiment analysis.

## Model Evaluation from Prediction Results DNN TFIDF GWO
"""

correct_predictions_df = valid_df.iloc[y_valid == val_pred]
incorrect_predictions_df = valid_df.iloc[y_valid != val_pred]

print("Correct Predictions:")
for index, row in correct_predictions_df.head().iterrows():
    print(f"Text: {row['Text']}")
    print(f"Actual Label: {row['Sentiment']}")
    print(f"Predicted Label: {le.classes_[val_pred[index]]}")
    print()

"""**Penjelasan insight:** Berdasarkan correct predictions di atas, diperoleh beberapa insight yaitu:
1.  Model DNN TFIDF yang telah dituning menggunakan GWO mudah mengenali sentimen positif yang jelas, misalnya ada kata atau frasa seperti “enak”, “harga murah”, “porsi banyak”, “sangat jangkau”. Pola-pola ini membuat model yakin bahwa teks tersebut positif.

2. Kalimat negatif yang mengandung keluhan atau kata kasar juga diprediksi dengan benar. Kata seperti “bejad”, “cabul”, “sempit”, “tidak ada” menjadi indikator kuat bagi model.

3. Model peka terhadap konteks, bukan hanya satu kata. Kalimat panjang atau tidak baku tetap dapat dipahami sebagai positif bila isinya menggambarkan pengalaman yang baik.

4. Model stabil di berbagai domain, baik review restoran, hotel, maupun komentar politik. Selama nada emosinya jelas, model mudah menentukan sentimen.
"""

print("Incorrect Predictions:")
for index, row in incorrect_predictions_df.head().iterrows():
    print(f"Text: {row['Text']}")
    print(f"Actual Label: {row['Sentiment']}")
    print(f"Predicted Label: {le.classes_[val_pred[index]]}")
    print()

"""**Penjelasan insight:** Berdasarkan incorrect predictions di atas, diperoleh beberapa insight yaitu:
1. Kalimat netral dianggap positif karena ada kata bernada positif yang berdiri sendiri.
Contoh: “upaya kerek tingkat pilih elektabilitas”
Model melihat kata-kata seperti “upaya” atau “pilih”, yang sering muncul pada teks positif, sehingga mengira ini kalimat positif meskipun sebenarnya netral.

2. Kalimat negatif sangat pendek sehingga TF-IDF tidak memiliki cukup konteks.
Contoh: “tidak enak”
Karena hanya dua kata, bobot kata “enak” yang biasanya positif lebih dominan, sehingga model ‘tertipu’ dan memprediksi positif.

3. Kalimat positif dengan campuran kata bernada biasa/netral diprediksi negatif.
Contoh:
“desain nya … biasa saja tapi iklan nya ini bagus banget”
Model menangkap “biasa saja” sebagai sinyal negatif dan tidak cukup memberi bobot pada bagian “bagus banget”.

4. Kalimat negatif dengan cerita bertahap diprediksi positif karena bagian awal bersifat positif.
Contoh:
“mau work out biar bisa bakar lemak… eh… tempat nya nyata tidak nyaman”
Model mungkin fokus pada segmen awal yang netral–positif, sehingga melewatkan bagian akhir yang mengandung keluhan.

5. Kalimat positif tapi mengandung kata negatif di awal membuat model tertukar.
Contoh:
“tidak pernah kapok… terus langgan… cepat sampai”
Frasa “tidak pernah” memicu pola negatif, padahal maknanya positif secara keseluruhan. TF-IDF tidak memahami makna “tidak kapok” sebagai ekspresi puas.

## Save Model TF-IDF GWO Tuning
"""

best_gwo_model.save("final_tfidf_gwo_model.h5")
print("TF-IDF GWO model saved as final_tfidf_gwo_model.h5")

import pickle

with open("tfidf_vectorizer.pkl", "wb") as f:
    pickle.dump(tfidf, f)

with open("label_encoder.pkl", "wb") as f:
    pickle.dump(le, f)

with open("dnn_tfidf_gwo_history.pkl", "wb") as f:
    pickle.dump(best_history.history, f)

print("DNN TF-IDF GWO training history saved as dnn_tfidf_gwo_history.pkl")

"""# Modeling DNN using Word2Vec"""

texts_all = pd.concat([train_df['Text'], valid_df['Text'], test_df['Text']]).tolist()
sentences = [t.split() for t in texts_all]

w2v_model = Word2Vec(
    sentences,
    vector_size=100,
    window=5,
    min_count=2,
    workers=4,
    epochs=10,
    seed=42
)
embedding_dim = w2v_model.wv.vector_size
print("W2V vocab size:", len(w2v_model.wv))

max_words = 30000
tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(train_df['Text'])

X_train_seq = tokenizer.texts_to_sequences(train_df['Text'])
X_valid_seq = tokenizer.texts_to_sequences(valid_df['Text'])
X_test_seq  = tokenizer.texts_to_sequences(test_df['Text'])

maxlen = 100
X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post')
X_valid_pad = pad_sequences(X_valid_seq, maxlen=maxlen, padding='post')
X_test_pad  = pad_sequences(X_test_seq,  maxlen=maxlen, padding='post')

num_words = min(max_words, len(tokenizer.word_index) + 1)
print("Num words:", num_words, "Maxlen:", maxlen)

embedding_matrix = np.zeros((num_words, embedding_dim))
for word, i in tokenizer.word_index.items():
    if i >= num_words:
        continue
    if word in w2v_model.wv:
        embedding_matrix[i] = w2v_model.wv[word]
    else:
        embedding_matrix[i] = np.random.normal(scale=0.01, size=(embedding_dim,))

def build_w2v_dnn(num_words, embedding_dim, maxlen, embedding_matrix,
                  n_neurons=128, dropout=0.3, lr=1e-3, trainable=False):
    model = keras.Sequential([
        layers.Embedding(input_dim=num_words,
                         output_dim=embedding_dim,
                         input_length=maxlen,
                         weights=[embedding_matrix],
                         trainable=trainable),
        layers.GlobalAveragePooling1D(),
        layers.Dense(n_neurons, activation='relu'),
        layers.Dropout(dropout),
        layers.Dense(64, activation='relu'),
        layers.Dropout(dropout),
        layers.Dense(3, activation='softmax')
    ])
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

base_w2v = build_w2v_dnn(num_words, embedding_dim, maxlen, embedding_matrix,
                         n_neurons=128, dropout=0.3, lr=1e-3, trainable=False)

es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
base_w2v.fit(X_train_pad, y_train,
             validation_data=(X_valid_pad, y_valid),
             epochs=10, batch_size=32, callbacks=[es], verbose=1)

val_pred_prob = base_w2v.predict(X_valid_pad)
val_pred = np.argmax(val_pred_prob, axis=1)

print("Validation Accuracy (DNN W2V):", accuracy_score(y_valid, val_pred))
print(classification_report(y_valid, val_pred, target_names=le.classes_))

val_cm = confusion_matrix(y_valid, val_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Validation Confusion Matrix (DNN W2V)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""**Penjelasan insight:** Berdasarkan hasil evaluasi model DNN yang dilatih menggunakan Word2Vec (W2V), diperoleh beberapa insight sebagai berikut:
1. Validation accuracy sebesar 0.8452 menunjukkan bahwa model mampu memprediksi sentimen dengan cukup baik, meskipun performanya masih berada di bawah model DNN TF-IDF. Dengan akurasi sekitar 84.5%, sebagian besar data validasi diklasifikasikan dengan benar.

2. Performa terbaik ditunjukkan pada kelas positive.
Model mencapai precision 0.91 dan recall 0.88, menandakan bahwa prediksi untuk kelas positive jarang salah, dan sebagian besar data positive dapat dikenali dengan baik oleh model. Support kelas positive yang besar (735 data) memberikan banyak contoh bagi Word2Vec untuk mempelajari representasi semantik kata dalam review positif.

3. Kelas negative menunjukkan performa cukup stabil dengan precision 0.76 dan recall 0.82. Recall yang cukup tinggi menunjukkan bahwa sebagian besar teks negatif berhasil terdeteksi sebagai negative, walaupun precision turun karena masih terdapat sejumlah data negatif yang disalahprediksi menjadi positive (54 data) atau neutral (16 data). Hal ini dapat terjadi karena representasi Word2Vec lebih kontekstual, namun kata bernada negatif kadang memiliki kemiripan semantik dengan konteks netral atau positif.

4. Kelas neutral tetap menjadi kelas yang paling sulit dibedakan, terlihat dari precision 0.75, recall 0.69, dan F1-score yang menjadi yang terendah (0.72). Pada confusion matrix terlihat bahwa:
    - 33 data neutral dianggap negative
    - 7 data neutral dianggap positive
    - 14 data positive dianggap neutral
    - 16 data negative dianggap neutral

    Kesulitan ini wajar karena banyak kalimat neutral memiliki pola yang mirip dengan kalimat negatif atau positif, tetapi tanpa adanya kata emosional yang jelas. Word2Vec yang berbasis distribusi kata cenderung mengelompokkan kata yang sering muncul bersama, sehingga kalimat netral yang mengandung kata-kata kontekstual dapat tertarik ke kelas lain.

5. Model sedikit menunjukkan bias ke kelas positive, terlihat dari jumlah prediksi benar kelas positive yang sangat besar (650), tetapi tetap terjadi salah klasifikasi 71 data positive menjadi negative. Hal ini menunjukkan bahwa ketika konteksnya kurang jelas atau mengandung kata bernuansa negatif di beberapa bagian, model masih berpotensi salah menafsirkan arah sentimen.

6. Nilai macro average dan weighted average menunjukkan bahwa performa model konsisten antar kelas, namun tetap lebih dominan di kelas positif.
Dengan macro F1 0.80 dan weighted F1 0.85, terlihat bahwa secara keseluruhan model bekerja cukup baik meskipun tidak sekuat model berbasis TF-IDF dalam menangani kelas neutral dan negative.

Dengan demikian dapat disimpulkan bahwa model DNN W2V mampu memahami konteks kalimat lebih dalam melalui embedding Word2Vec dan memberikan hasil yang baik terutama pada kelas positive. Namun, performanya menurun pada kelas neutral dan sebagian negative karena Word2Vec lebih sensitif pada kemiripan konteks kata daripada kekuatan kata emosional tertentu. Dengan akurasi sekitar 84.5%, model ini layak digunakan tetapi masih dapat ditingkatkan, khususnya dalam membedakan kalimat neutral yang sering bersifat ambigu.

## Hyperparameter tuning using GWO for DNN W2V
"""

def fitness_w2v(params):
    neurons, dropout, lr, batch, trainable_flag = params
    neurons = int(neurons)
    batch = int(batch)
    trainable = bool(round(trainable_flag))

    model = build_w2v_dnn(num_words=num_words,
                          embedding_dim=embedding_dim,
                          maxlen=maxlen,
                          embedding_matrix=embedding_matrix,
                          n_neurons=neurons,
                          dropout=float(dropout),
                          lr=float(lr),
                          trainable=trainable)

    model.fit(X_train_pad, y_train,
              validation_data=(X_valid_pad, y_valid),
              epochs=6, batch_size=batch, verbose=0)

    pred_val = np.argmax(model.predict(X_valid_pad), axis=1)
    acc = accuracy_score(y_valid, pred_val)
    return 1 - acc, model

def GWO_w2v(num_wolves=5, max_iter=5):
    lb = np.array([64, 0.1, 1e-5, 16, 0])
    ub = np.array([512, 0.5, 1e-2, 64, 1])

    wolves = lb + (ub - lb) * np.random.rand(num_wolves, 5)

    alpha = beta = delta = None
    alpha_score = beta_score = delta_score = float("inf")
    best_model = None
    best_params = None

    for it in range(max_iter):
        print(f"[GWO-W2V] Iter {it+1}/{max_iter}")
        for i in range(num_wolves):
            params = wolves[i]
            score, model = fitness_w2v(params)

            if score < alpha_score:
                alpha_score = score
                alpha = params.copy()
                best_model = keras.models.clone_model(model)
                best_model.set_weights(model.get_weights())
                best_params = alpha.copy()
            elif score < beta_score:
                beta_score = score
                beta = params.copy()
            elif score < delta_score:
                delta_score = score
                delta = params.copy()

        a = 2 - it * (2 / max_iter)

        if alpha is None:
            alpha = wolves[0].copy()
        if beta is None:
            beta = wolves[1 % num_wolves].copy()
        if delta is None:
            delta = wolves[2 % num_wolves].copy()

        for i in range(num_wolves):
            for j in range(5):
                r1, r2 = np.random.rand(), np.random.rand()
                A1 = 2 * a * r1 - a
                C1 = 2 * r2
                D_alpha = abs(C1 * alpha[j] - wolves[i][j])
                X1 = alpha[j] - A1 * D_alpha

                r1, r2 = np.random.rand(), np.random.rand()
                A2 = 2 * a * r1 - a
                C2 = 2 * r2
                D_beta = abs(C2 * beta[j] - wolves[i][j])
                X2 = beta[j] - A2 * D_beta

                r1, r2 = np.random.rand(), np.random.rand()
                A3 = 2 * a * r1 - a
                C3 = 2 * r2
                D_delta = abs(C3 * delta[j] - wolves[i][j])
                X3 = delta[j] - A3 * D_delta

                wolves[i][j] = (X1 + X2 + X3) / 3.0

        wolves = np.clip(wolves, lb, ub)

    return best_params, best_model

best_params_w2v, best_gwo_model_w2v = GWO_w2v(num_wolves=5, max_iter=5)

print("Best params W2V:", best_params_w2v)
print("Neurons:", int(best_params_w2v[0]),
      "Dropout:", float(best_params_w2v[1]),
      "LR:", float(best_params_w2v[2]),
      "Batch:", int(best_params_w2v[3]),
      "TrainableEmb:", bool(round(best_params_w2v[4])))

val_pred_prob = best_gwo_model_w2v.predict(X_valid_pad)
val_pred = np.argmax(val_pred_prob, axis=1)

print("Validation Accuracy (DNN W2V GWO):", accuracy_score(y_valid, val_pred))
print(classification_report(y_valid, val_pred, target_names=le.classes_))

val_cm = confusion_matrix(y_valid, val_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Validation Confusion Matrix (DNN W2V GWO)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""**Penjelasan insight:** Berdasarkan hasil evaluasi model DNN dengan embedding Word2Vec yang dioptimasi menggunakan Grey Wolf Optimizer (GWO), diperoleh insight sebagai berikut:
1. Model mencapai validation accuracy sebesar 0.8714, yang lebih tinggi dibandingkan model DNN W2V tanpa optimasi. Hal ini menunjukkan bahwa optimasi hyperparameter dengan GWO memberikan perbaikan performa yang signifikan, sehingga model mampu mempelajari pola sentimen dengan lebih efektif.

2. Performa kelas positive menjadi yang terbaik, dengan precision 0.91 dan recall 0.91, menunjukkan bahwa model sangat konsisten dalam mengenali sentimen positif. Sebagian besar komentar positif berhasil diklasifikasikan dengan benar (667 data benar diprediksi), menunjukkan bahwa W2V + GWO dapat menangkap konteks kata yang sering muncul pada ulasan positif secara lebih stabil.

3. Kelas negative stabil dengan precision 0.83 dan recall 0.84, lebih baik dibandingkan model W2V biasa.
Hal ini terlihat dari penurunan kesalahan prediksi pada kelas negative, meskipun masih terdapat:
    - 51 data negative diprediksi sebagai positive
    - 13 data negative diprediksi sebagai neutral

    Model mampu mengidentifikasi sebagian besar ulasan negatif, terutama yang mengandung ekspresi keluhan yang eksplisit.

4. Kelas neutral tetap menjadi yang paling sulit dibedakan, dengan precision 0.80, recall 0.77, dan F1-score 0.78.
Pada confusion matrix terlihat bahwa:
    - 11 data neutral diprediksi negative
    - 19 data neutral diprediksi positive

    Kesalahan ini umum terjadi karena banyak komentar neutral memiliki struktur kalimat yang berada di antara tone positif dan negatif. Word2Vec yang berbasis distribusi kata juga membuat kalimat neutral lebih mudah “tertarik” ke kelas lain yang secara semantik lebih dominan.

5. Model menunjukkan kecenderungan yang lebih seimbang dibandingkan W2V tanpa optimasi.
GWO membantu mengatur bobot jaringan (learning rate, batch size, jumlah neuron) sehingga hasil prediksi untuk ketiga kelas menjadi lebih proporsional. Hal ini tercermin dari macro average F1 sebesar 0.84, meningkat dari model sebelumnya (0.80).

6. Tidak ada bias kuat ke kelas positive, meskipun support yang besar tetap memberi keuntungan pada pembelajaran kelas tersebut. Model GWO menurunkan jumlah prediksi salah yang berlebihan pada kelas positive maupun negative, sehingga menghasilkan prediksi yang lebih stabil.

Oleh karena itu, dapat dikatakan bahwa model DNN W2V yang dioptimasi menggunakan Grey Wolf Optimizer (GWO) memberikan peningkatan performa yang jelas dibandingkan versi tanpa optimasi. Dengan akurasi validasi 87.14%, model bekerja sangat baik terutama pada kelas positive dan negative. Kelas neutral masih menjadi tantangan karena ambiguitas alami pada teksnya, namun secara keseluruhan model menunjukkan peningkatan signifikan dalam keseimbangan prediksi dan pemahaman konteks sentimen.

## Model Evaluation from Prediction Results DNN W2V GWO
"""

val_pred_prob = best_gwo_model_w2v.predict(X_valid_pad)
val_pred = np.argmax(val_pred_prob, axis=1)

print("Correct Predictions:")
for index, row in correct_predictions_df.head().iterrows():
    print(f"Text: {row['Text']}")
    print(f"Actual Label: {row['Sentiment']}")
    print(f"Predicted Label: {le.classes_[val_pred[index]]}")
    print()

"""**Penjelasan insight:**
1. Model berhasil mengenali pujian yang dominan meskipun kalimat panjang dan bercampur deskripsi.
Contoh: ulasan restoran dengan banyak detail makanan.
Model dapat menangkap kata-kata seperti “enak”, “murah”, “variatif”, sehingga tetap mengklasifikasi sebagai positif meskipun struktur kalimat rumit.

2. Model konsisten membaca pola ulasan positif yang umum pada review makanan.
Contoh: “porsi banyak dan kenyang”
Istilah seperti “porsi banyak”, “kenyang”, “harga terjangkau” merupakan indikator kuat yang sering muncul pada sentimen positif sehingga mudah ditangkap oleh model.

3. Model dapat mengidentifikasi sentimen negatif yang eksplisit.
Contoh: kalimat bernada kemarahan atau kecaman politik.
Kata-kata seperti “bejad”, “cabul”, “tenggelamkan” sudah sangat kuat bernada negatif, sehingga model memprediksi dengan tepat.

4. Model mengenali pola positif berbasis fasilitas atau pengalaman menyenangkan.
Contoh: “harga jangkau”, “ada live musik”, “menyenangkan”.
Frasa-frasa ini sering muncul dalam ulasan positif sehingga model bisa membaca konteks dengan baik.

5. Model dapat membaca keluhan yang jelas meskipun kalimat informal.
Contoh: “kamar nya sempit”, “tidak ada tempat simpan barang”.
Kata deskriptif negatif seperti “sempit”, “tidak ada”, “malah tambah” memiliki bobot kuat sehingga membantu model menebak negatif dengan benar.
"""

print("Incorrect Predictions:")
for index, row in incorrect_predictions_df.head().iterrows():
    print(f"Text: {row['Text']}")
    print(f"Actual Label: {row['Sentiment']}")
    print(f"Predicted Label: {le.classes_[val_pred[index]]}")
    print()

"""**Penjelasan insight:**
1. Kalimat netral terbaca positif karena ada kata bernada positif yang berdiri sendiri.
Model menangkap kata seperti “upaya” dan “pilih” yang sering muncul di konteks positif, sehingga kalimat netral salah diklasifikasikan sebagai positif.

2. Kalimat negatif yang terlalu pendek tidak memberi cukup konteks bagi model.
Pada contoh “tidak enak”, kata “enak” yang biasanya positif memiliki bobot lebih tinggi daripada kata “tidak”, sehingga model terjebak memprediksi positif.

3. Kalimat positif dengan campuran frasa bernada datar/negatif terbaca sebagai negatif.
Frasa “biasa saja” dianggap sebagai sinyal negatif, sehingga bagian positif “bagus banget” tidak cukup kuat menaikkan prediksi menjadi positif.

4. Kalimat negatif yang memiliki pembuka netral–positif membingungkan model.
Model memberi bobot lebih besar pada bagian awal (“mau work out”, “bakar lemak”), sehingga keluhan di bagian akhir (“tidak nyaman”) tidak terbaca dominan.

5. Kalimat positif yang mengandung kata negatif di awal memicu prediksi salah.
Frasa “tidak pernah kapok” secara literal mengandung kata “tidak”, sehingga model salah menganggapnya sebagai sentimen negatif, meski maknanya positif.

## Save Model DNN W2V GWO
"""

best_gwo_model_w2v.save("final_w2v_gwo_model.h5")
print("Saved final_w2v_gwo_model.h5")

with open("w2v_tokenizer.pkl", "wb") as f:
    pickle.dump(tokenizer, f)
print("Tokenizer saved as w2v_tokenizer.pkl")

with open("label_encoder.pkl", "wb") as f:
    pickle.dump(le, f)
print("Label encoder saved as label_encoder.pkl")

"""# Model Compare"""

y_test_encoded = le.transform(test_df['Sentiment'])
print("Encoded test labels distribution:", np.bincount(y_test_encoded))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import numpy as np

models_dict = {
    "DNN TF-IDF Base": (base_model, X_test_tfidf),
    "DNN TF-IDF GWO": (best_gwo_model, X_test_tfidf),
    "DNN W2V Base": (base_w2v, X_test_pad),
    "DNN W2V GWO": (best_gwo_model_w2v, X_test_pad)
}

for name, (model, X_test) in models_dict.items():
    print(f"\n=== {name} ===")

    y_pred_prob = model.predict(X_test)
    y_pred = np.argmax(y_pred_prob, axis=1)

    print("Test Accuracy:", accuracy_score(y_test_encoded, y_pred))
    print(classification_report(y_test_encoded, y_pred, target_names=le.classes_, zero_division=0))

    cm = confusion_matrix(y_test_encoded, y_pred)
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=le.classes_, yticklabels=le.classes_)
    plt.title(f"Confusion Matrix ({name})")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    unique, counts = np.unique(y_pred, return_counts=True)
    print("Prediction distribution:", dict(zip(le.classes_, counts)))

"""**Penjelasan insight:**
1. DNN TF-IDF Base
Model baseline dengan TF-IDF menunjukkan performa yang stabil dengan akurasi 0.774, menandakan bahwa representasi berbasis frekuensi sudah cukup efektif untuk memotret kata-kata bernada sentimen.
Insight penting:
    - Recall kelas negative sangat tinggi (0.91), model sangat sensitif terhadap pola kata keluhan, sehingga hampir semua teks negatif terdeteksi.
    - Recall kelas positive turun (0.72), model terkadang melewatkan ekspresi positif yang tidak eksplisit.
    - Kelas neutral lemah (F1 0.62), TF-IDF kesulitan membedakan netral dari konteks campuran. Ini umum terjadi karena netral memiliki distribusi kata yang mirip dengan dua kelas lain
    
    Secara keseluruhan, TF-IDF Base sudah memberikan fondasi kuat, tetapi belum optimal dalam menangani konteks kalimat kompleks.

2. Dengan tuning hyperparameter menggunakan GWO, performa meningkat tipis menjadi 0.776, tetapi pola perbaikan menunjukkan bahwa tuning membantu stabilitas model.
    - Precision dan recall untuk negative naik sedikit, membuat model lebih seimbang dalam mendeteksi teks negatif tanpa over-flagging.
    - Kinerja neutral tetap rendah (F1 0.60), menunjukkan bahwa keterbatasan TF-IDF berasal dari representasi, bukan dari parameter model.
    - Kelas positive menjadi lebih stabil (recall naik dari 0.72 menjadi 0.77), memperbaiki miss pada teks positif halus.
    - GWO memberikan perbaikan kecil namun konsisten: TF-IDF sebagai representasi tidak berubah, jadi peningkatan murni datang dari tuning arsitektur/model capacity.

3. DNN W2V Base
Model ini memiliki performa terendah dengan akurasi 0.688. Dengan hal ini menunjukkan bahwa Word2Vec sangat sensitif terhadap kualitas preprocessing.
    - Recall negative sangat tinggi (0.97) tetapi precision rendah (0.61), artinya model sering “overpredict negatif”.
    - Recall positive jatuh drastis (0.53), model gagal menangkap sinyal positif jika konteks tidak jelas atau bercampur.
    - Kelas neutral sangat buruk (F1 0.53), konteks Word2Vec tidak terbaca baik jika teks tidak dibersihkan secara optimal (slang, typo, negasi).
    - W2V Base menunjukkan bahwa embedding berbasis konteks bisa salah memetakan kata karena representasi yang tidak konsisten.

4. DNN W2V + GWO
Dengan tuning menggunakan GWO, performa meningkat signifikan menjadi 0.778, hampir menyamai TF-IDF GWO.
    - Lonjakan akurasi dari 0.688 menjadi 0.778 menunjukkan bahwa Word2Vec lebih diuntungkan oleh tuning hyperparameter dibanding TF-IDF.
    - Recall positive naik dari 0.53 menjadi 0.83, memperbaiki masalah terbesar pada W2V Base.
    - Negative lebih stabil (precision 0.81, recall 0.85), tidak lagi overpredict negative seperti model base.
    - Neutral tetap kelas tersulit (F1 0.58) karena distribusi kata netral memang cenderung ambigu.
    
    Setelah embedding diperkuat oleh tuning, W2V dapat mendekati performa TF-IDF, bahkan lebih seimbang dalam beberapa metrik.

Dapat disimpulkan insight utama dari semua model ialah:
1. TF-IDF lebih stabil, tetapi peningkatan dari tuning kecil (model tidak terlalu sensitif terhadap perubahan parameter).
2. Word2Vec sangat bergantung pada preprocessing, tetapi potensi performanya lebih besar, terlihat setelah GWO memperbaiki parameter model.
3. Kelas neutral adalah tantangan di semua model, menandakan perlunya pendekatan khusus seperti:
    - handling negation lebih baik,
    - cleaning stopwords yang mengandung sentimen tersembunyi,   
    - augmentasi data netral.
4. Model cenderung overpredict negative ketika konteks kurang jelas, terutama di Word2Vec base.
5. Performa terbaik dicapai oleh TF-IDF GWO dan W2V GWO, menunjukkan bahwa tuning sangat penting dalam DNN untuk teks.
"""

models_dict = {
    "TFIDF_Base": (base_model, X_valid_tfidf, X_test_tfidf),
    "TFIDF_GWO": (best_gwo_model, X_valid_tfidf, X_test_tfidf),
    "W2V_Base": (base_w2v, X_valid_pad, X_test_pad),
    "W2V_GWO": (best_gwo_model_w2v, X_valid_pad, X_test_pad)
}

rows = []

for name, (model, X_val, X_test) in models_dict.items():
    val_pred = np.argmax(model.predict(X_val), axis=1)
    test_pred = np.argmax(model.predict(X_test), axis=1)

    rows.append({
        "model": name,
        "val_acc": accuracy_score(y_valid, val_pred),
        "test_acc": accuracy_score(y_test_encoded, test_pred),
        "test_f1_macro": f1_score(y_test_encoded, test_pred, average='macro'),
        "test_precision_macro": precision_score(y_test_encoded, test_pred, average='macro', zero_division=0),
        "test_recall_macro": recall_score(y_test_encoded, test_pred, average='macro', zero_division=0)
    })

df_results = pd.DataFrame(rows).sort_values("test_acc", ascending=False).reset_index(drop=True)
display(df_results)

df_results.to_csv("model_comparison_results.csv", index=False)
print("Saved as model_comparison_results.csv")

"""**Penjelasan insight:**
1. TF-IDF lebih stabil daripada Word2Vec.
Baik pada model Base maupun GWO, TF-IDF menghasilkan test accuracy yang lebih konsisten (0.774–0.776). Ini menunjukkan bahwa TF-IDF lebih tahan terhadap noise dan variasi bahasa.

2. Word2Vec sangat bergantung pada tuning.
W2V Base memiliki performa terendah (test acc 0.688), tetapi setelah GWO tuning naik signifikan ke 0.778. Artinya, embedding berbasis konteks memerlukan parameter yang lebih optimal agar bisa bekerja baik.

3. GWO memberikan peningkatan paling besar untuk Word2Vec.
Pada TF-IDF, peningkatan dari GWO relatif kecil. Namun untuk Word2Vec, peningkatannya sangat besar, terutama pada f1-macro (0.645 → 0.734). Ini menegaskan bahwa tuning berperan besar dalam meningkatkan kualitas representasi konteks.

4. Kelas neutral tetap yang paling sulit untuk semua model.
Hal ini tercermin dari nilai recall macro yang selalu paling rendah, terutama pada W2V Base (0.636). Model kesulitan membedakan teks netral dari positif/negatif.

5. Performa terbaik secara keseluruhan ada pada W2V GWO dan TF-IDF GWO.
Kedua model ini memiliki f1-macro, precision, dan recall yang paling seimbang, sehingga lebih reliabel untuk sentimen real-world.
"""

plt.figure(figsize=(8,5))
plt.barh(df_results["model"], df_results["test_acc"], color="skyblue")
plt.xlabel("Test Accuracy")
plt.title("Model Comparison (Accuracy) – Horizontal")
plt.tight_layout()
plt.show()

"""**Penjelasan insight:** Grafik menunjukkan bahwa model dengan performa terendah adalah W2V_Base, yang hanya mencapai akurasi sekitar 0.69. Setelah dilakukan optimasi dengan GWO, performanya meningkat signifikan, terlihat pada W2V_GWO yang mendekati akurasi 0.78. Sementara itu, model berbasis TF-IDF sudah cukup stabil sejak awal, dengan TFIDF_Base dan TFIDF_GWO keduanya berada pada kisaran akurasi 0.77–0.78. Secara keseluruhan, optimasi GWO memberikan dampak paling besar pada Word2Vec, sedangkan pada TF-IDF efeknya lebih kecil karena model dasarnya sudah kuat."""

f1_col = [col for col in df_results.columns if "f1" in col.lower()][0]
print("F1 column detected:", f1_col)

plt.figure(figsize=(8,5))
plt.bar(df_results["model"], df_results[f1_col], color="salmon")
plt.xlabel("Model")
plt.ylabel("Macro F1-Score")
plt.title("Model Comparison: F1-Score")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

"""**Penjelasan insight:** Grafik F1-score menunjukkan bahwa tiga model, di antaranya ialah W2V_GWO, TFIDF_GWO, dan TFIDF_Base memiliki performa yang relatif seimbang di kisaran 0.73–0.75. Hal ini mengindikasikan bahwa baik penggunaan TF-IDF maupun optimasi GWO mampu menjaga keseimbangan antara precision dan recall. Sebaliknya, W2V_Base terlihat tertinggal cukup jauh dengan F1-score sekitar 0.65, menandakan bahwa model Word2Vec tanpa optimasi kurang mampu menangkap pola sentimen secara konsisten. Dengan demikian, optimasi GWO terbukti memberikan peningkatan signifikan bagi Word2Vec, sementara untuk TF-IDF perbaikan performanya lebih moderat.

# Final Summary
Berdasarkan eksperimen yang telah saya lakukan di beberapa model, diperoleh kesimpulan akhir sebagai berikut:
1. TF-IDF dan W2V yang dioptimasi GWO memberikan performa terbaik, baik pada akurasi maupun F1-score, menunjukkan bahwa optimasi hyperparameter berpengaruh signifikan terhadap kualitas model.

2. Model TF-IDF (Base maupun GWO) konsisten lebih stabil dibanding W2V Base, terutama karena TF-IDF lebih tahan terhadap data noisy dan variasi teks.

3. W2V Base memiliki performa paling rendah, menegaskan bahwa embedding berbasis konteks sangat bergantung pada preprocessing yang baik dan parameter yang tepat.

4. GWO meningkatkan performa Word2Vec secara signifikan, menutup celah performa yang sebelumnya besar dibanding TF-IDF.

Secara keseluruhan, kualitas preprocessing dan tuning berperan langsung dalam meningkatkan akurasi, F1-score, dan konsistensi model.
"""